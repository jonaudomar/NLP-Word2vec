{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run your first RNN for NLP\n",
    "- Get a first taste of what an embedding is\n",
    "\n",
    "<hr>\n",
    "\n",
    "Words are not something you can easily feed to a Neural Network. For this reason, we have to convert them to something more meaningful. \n",
    "\n",
    "And this is exactly what _Embeddings_ are for! They map any word onto a vectorial representation (this a fancy way to represent each word with a vector ;) ). For instance, the word `dog` can be represented by the vector $(w_1, w_2, ..., w_n)$ in the embedding space, and we will learn the weights $(w_k)_k$.\n",
    "\n",
    "So let's just do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Warning** ⚠️ The `load_data` function has a `percentage_of_sentences` argument. Depending on your computer, there are chances that too many sentences will make your compute slow down, or even freeze - your RAM can overflow. For that reason, **you should start with 10% of the sentences** and see if your computer handles it. Otherwise, rerun with a lower number. \n",
    "\n",
    "⚠️ **DISCLAIMER** ⚠️ **No need to play _who has the biggest_ (RAM) !** The idea is to get to run your models quickly to prototype. Even in real life, it is recommended that you start with a subset of your data to loop and debug quickly. So increase the number only if you are into getting the best accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:16:59.971785Z",
     "iopub.status.busy": "2025-08-26T13:16:59.971198Z",
     "iopub.status.idle": "2025-08-26T13:19:09.442279Z",
     "shell.execute_reply": "2025-08-26T13:19:09.441598Z",
     "shell.execute_reply.started": "2025-08-26T13:16:59.971766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 15:17:00.859142: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-26 15:17:00.871949: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-26 15:17:00.961639: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-26 15:17:01.060023: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-26 15:17:01.156092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-26 15:17:01.156549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-26 15:17:01.300665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-26 15:17:02.302657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-08-26 15:17:04.804861: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/jonathand/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057fabe0bd1f403c888cdf81b1308d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179f44cf154d4197b9674470894cdc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1066dd03ceb4fbeb5cc9fab20612837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2324b8dbcd439783d20559bb99d8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679e0ddd860345f6bf3fc87a9248a398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jonathand/tensorflow_datasets/imdb_reviews/plain_text/incomplete.NLDZYI_1.0.0/imdb_reviews-tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687b4699ce494d2c9d95cf3c6c122b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ae515742e54d9aaa3f7aad79eeabbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jonathand/tensorflow_datasets/imdb_reviews/plain_text/incomplete.NLDZYI_1.0.0/imdb_reviews-tes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8f39ddd07841d89b9e0d96ec5ddc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0370820b24584a178ef111a448d18490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jonathand/tensorflow_datasets/imdb_reviews/plain_text/incomplete.NLDZYI_1.0.0/imdb_reviews-uns…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/jonathand/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 15:19:08.000003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-26 15:19:08.001818: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "### Just run this cell to load the data ###\n",
    "###########################################\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "\n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "\n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "\n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "\n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have loaded the data, let's check it out!\n",
    "\n",
    "❓ **Question** ❓ You can play with the data here. In particular, `X_train` and `X_test` are lists of sentences. Let's print some of them, with their respective label stored in `y_train` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:19:29.492084Z",
     "iopub.status.busy": "2025-08-26T13:19:29.491631Z",
     "iopub.status.idle": "2025-08-26T13:19:29.495378Z",
     "shell.execute_reply": "2025-08-26T13:19:29.494846Z",
     "shell.execute_reply.started": "2025-08-26T13:19:29.492062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['this', 'was', 'an', 'absolutely', 'terrible', 'movie', \"don't\", 'be', 'lured', 'in', 'by', 'christopher', 'walken', 'or', 'michael', 'ironside', 'both', 'are', 'great', 'actors', 'but', 'this', 'must', 'simply', 'be', 'their', 'worst', 'role', 'in', 'history', 'even', 'their', 'great', 'acting', 'could', 'not', 'redeem', 'this', \"movie's\", 'ridiculous', 'storyline', 'this', 'movie', 'is', 'an', 'early', 'nineties', 'us', 'propaganda', 'piece', 'the', 'most', 'pathetic', 'scenes', 'were', 'those', 'when', 'the', 'columbian', 'rebels', 'were', 'making', 'their', 'cases', 'for', 'revolutions', 'maria', 'conchita', 'alonso', 'appeared', 'phony', 'and', 'her', 'pseudo', 'love', 'affair', 'with', 'walken', 'was', 'nothing', 'but', 'a', 'pathetic', 'emotional', 'plug', 'in', 'a', 'movie', 'that', 'was', 'devoid', 'of', 'any', 'real', 'meaning', 'i', 'am', 'disappointed', 'that', 'there', 'are', 'movies', 'like', 'this', 'ruining', \"actor's\", 'like', 'christopher', \"walken's\", 'good', 'name', 'i', 'could', 'barely', 'sit', 'through', 'it']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0], X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:19:51.924204Z",
     "iopub.status.busy": "2025-08-26T13:19:51.923183Z",
     "iopub.status.idle": "2025-08-26T13:19:51.928309Z",
     "shell.execute_reply": "2025-08-26T13:19:51.927585Z",
     "shell.execute_reply.started": "2025-08-26T13:19:51.924177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [\"i'll\", 'give', 'it', 'a', 'two', 'because', 'it', 'has', 'a', 'lot', 'of', 'music', 'otherwise', 'it', 'would', 'be', 'a', 'one', 'br', 'br', 'i', 'saw', 'this', 'movie', 'for', 'the', 'first', 'time', 'tonight', 'and', \"it's\", 'the', 'first', 'road', 'picture', \"i've\", 'seen', 'i', 'was', 'expecting', 'waaaaay', 'better', 'robert', 'osborn', 'says', 'this', 'is', 'the', 'best', 'of', 'the', 'road', 'movies', 'if', \"that's\", 'true', 'i', \"needn't\", 'bother', 'to', 'see', 'the', 'others', 'the', 'best', 'thing', 'about', 'this', 'movie', 'is', 'that', 'it', 'has', 'a', 'lot', 'of', 'songs', 'in', 'the', 'first', 'half', 'but', \"that's\", 'balanced', 'out', 'by', 'only', 'one', 'production', 'number', 'with', 'dancing', 'in', 'the', 'entire', 'movie', 'br', 'br', 'i', \"didn't\", 'like', 'the', 'movie', 'neither', 'hope', 'nor', 'crosby', 'came', 'across', 'all', 'that', 'well', 'their', 'characters', \"weren't\", 'very', 'charming', 'the', 'movie', 'was', 'not', 'funny', 'at', 'all', 'most', 'of', 'the', 'dialog', 'was', 'just', 'lame', 'filler', 'there', \"wasn't\", 'much', 'action', 'there', \"wasn't\", 'much', 'spectacle', 'br', 'br', 'the', 'movie', \"wasn't\", 'what', 'i', 'expected', 'i', 'was', 'expecting', 'more', 'road', 'but', 'there', \"isn't\", 'much', 'they', 'quickly', 'make', 'it', 'to', 'the', 'palace', 'and', 'then', 'most', 'of', 'the', 'movie', 'takes', 'place', 'there', 'until', 'the', 'end', 'i', 'was', 'also', 'expecting', 'a', 'lot', 'more', 'of', 'the', 'famous', 'road', 'style', 'of', 'breaking', 'the', 'fourth', 'wall', 'wherein', 'the', 'characters', 'talk', 'directly', 'to', 'the', 'audience', 'or', 'comment', 'on', 'the', 'plot', 'there', 'was', 'only', 'about', '4', 'instances', 'of', 'that', 'one', 'of', 'those', 'is', 'an', 'example', 'of', 'the', 'non', 'funny', 'humor', 'of', 'this', 'script', 'br', 'br', 'hope', 'recaps', 'the', 'plot', 'up', 'to', 'now', 'to', 'crosby', 'crosby', 'i', 'know', 'all', 'that', 'hope', 'yeah', 'but', 'the', 'people', 'that', 'came', 'in', 'half', 'way', 'through', 'the', 'picture', \"don't\", 'crosby', 'you', 'mean', 'they', 'missed', 'my', 'song', 'br', 'br', 'those', 'are', 'two', 'weak', 'punchlines', 'but', 'at', 'least', 'they', 'are', 'actually', 'jokes', 'much', 'of', 'the', 'rest', 'of', 'the', 'script', \"doesn't\", 'even', 'have', 'any', 'jokes', 'an', 'example', 'is', 'br', 'br', 'crosby', 'remind', 'me', 'to', 'throw', 'you', 'a', 'piece', 'of', 'cheese', 'in', 'the', 'morning', 'indirectly', 'calling', 'hope', 'a', 'rat', 'br', 'br', \"that's\", 'not', 'funny', 'at', 'all', 'it', 'barely', 'even', 'qualifies', 'as', 'a', 'joke', 'but', \"that's\", 'the', 'kind', 'of', 'non', 'joke', 'dialog', 'that', 'carries', 'most', 'of', 'the', 'movie', 'many', 'of', 'the', 'scenes', \"don't\", 'even', 'come', 'that', 'close', 'to', 'a', 'joke', 'just', 'using', 'generic', 'uninteresting', 'dialog', 'like', 'br', 'br', 'crosby', 'hey', 'whadda', \"ya'\", 'take', 'me', 'for', 'you', 'think', 'that', 'you', 'can', 'just', 'throw', 'me', 'to', 'the', 'dogs', 'hope', 'well', 'why', 'not', 'you', 'did', 'it', 'to', 'me', \"didn't\", 'you', 'crosby', 'yeah', 'but', \"that's\", 'because', 'i', 'was', \"lookin'\", 'out', 'for', 'us', \"you're\", 'not', \"lookin'\", 'out', 'for', 'nobody', 'hope', 'oh', 'yeah', 'well', 'then', 'why', 'did', 'i', 'pay', 'the', 'check', 'br', 'br', 'the', 'above', 'is', 'just', 'from', 'my', 'memory', \"it's\", 'not', 'exact', 'but', 'it', 'illustrates', 'to', 'you', 'what', 'i', 'mean', 'br', 'br', 'and', 'so', 'on', 'just', 'generic', 'dialog', 'with', 'no', 'jokes', 'at', 'all', 'br', 'br', 'my', 'grade', 'a', 'waste', 'of', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[10], X_test[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LABELS**: the task is a binary classification problem:\n",
    "- label 0️⃣ corresponds to a <font color=red>negative</font> movie review\n",
    "- label 1️⃣ corresponds to a <font color=green>positive</font> movie review\n",
    "\n",
    "**INPUTS**: \n",
    "- 🧹 The data has been partially cleaned! So you don't have to worry about it in this exercise. \n",
    "- ❗️ But don't forget this step in real-life challenges. \n",
    "\n",
    "Remember that words are not computer-compatible materials? You have to tokenize them!\n",
    "\n",
    "❓ **Question** ❓ Run the following cell to tokenize your sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:22:08.135230Z",
     "iopub.status.busy": "2025-08-26T13:22:08.135010Z",
     "iopub.status.idle": "2025-08-26T13:22:08.419030Z",
     "shell.execute_reply": "2025-08-26T13:22:08.418452Z",
     "shell.execute_reply.started": "2025-08-26T13:22:08.135214Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# This initializes a Keras utilities that does all the tokenization for you\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# The tokenization learns a dictionary that maps a token (integer) to each word\n",
    "# It can be done only on the train set - we are not supposed to know the test set!\n",
    "# This tokenization also lowercases your words, apply some filters, and so on - you can check the doc if you want\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print some of the tokenized sentences to see what really happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:23:18.993257Z",
     "iopub.status.busy": "2025-08-26T13:23:18.992982Z",
     "iopub.status.idle": "2025-08-26T13:23:18.997802Z",
     "shell.execute_reply": "2025-08-26T13:23:18.997208Z",
     "shell.execute_reply.started": "2025-08-26T13:23:18.993243Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : i -> Token 9\n",
      "Word : enjoyed -> Token 579\n",
      "Word : this -> Token 11\n",
      "Word : movie -> Token 18\n",
      "Word : and -> Token 3\n",
      "Word : after -> Token 104\n",
      "Word : watching -> Token 155\n",
      "Word : it -> Token 10\n",
      "Word : it -> Token 10\n",
      "Word : made -> Token 90\n",
      "Word : me -> Token 65\n",
      "Word : wonder -> Token 574\n",
      "Word : just -> Token 40\n",
      "Word : how -> Token 84\n",
      "Word : many -> Token 107\n",
      "Word : 'caitlin -> Token 17238\n",
      "Word : rose's' -> Token 17239\n",
      "Word : exist -> Token 1632\n",
      "Word : in -> Token 8\n",
      "Word : the -> Token 1\n",
      "Word : world -> Token 189\n",
      "Word : how -> Token 84\n",
      "Word : many -> Token 107\n",
      "Word : other -> Token 82\n",
      "Word : girls -> Token 526\n",
      "Word : have -> Token 25\n",
      "Word : been -> Token 76\n",
      "Word : subjected -> Token 5574\n",
      "Word : to -> Token 5\n",
      "Word : this -> Token 11\n",
      "Word : sort -> Token 406\n",
      "Word : of -> Token 4\n",
      "Word : sexual -> Token 991\n",
      "Word : abuse -> Token 2393\n",
      "Word : and -> Token 3\n",
      "Word : torment -> Token 8200\n",
      "Word : by -> Token 31\n",
      "Word : classmates -> Token 7069\n",
      "Word : and -> Token 3\n",
      "Word : have -> Token 25\n"
     ]
    }
   ],
   "source": [
    "sentence_number = 100\n",
    "\n",
    "input_raw = X_train[sentence_number]\n",
    "input_token = X_train_token[sentence_number]\n",
    "\n",
    "for i in range(40):\n",
    "    print(f'Word : {input_raw[i]} -> Token {input_token[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary that maps each word to a token can be accessed with `tokenizer.word_index`\n",
    "    \n",
    "Let's create a `vocab_size` variable that stores the number of different words (=tokens) in the train set. This is called the _size of the vocabulary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:25:06.713610Z",
     "iopub.status.busy": "2025-08-26T13:25:06.713228Z",
     "iopub.status.idle": "2025-08-26T13:25:06.716805Z",
     "shell.execute_reply": "2025-08-26T13:25:06.716182Z",
     "shell.execute_reply.started": "2025-08-26T13:25:06.713594Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30419 different words in the train set\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "print(f'There are {vocab_size} different words in the train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `X_train_token` and `X_test_token` contain sequences of different lengths.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/NLP/padding.png\" alt='Padding example' width=\"700px\" />\n",
    "\n",
    "However, a neural network has to have a tensor as input. For this reason, we have to pad our data.\n",
    "\n",
    "❓ **Question** ❓  Pad your data with the `pad_sequences` function (documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)). Do not forget about the `dtype` and `padding` keywords (but do not use `maxlen` here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:27:18.706085Z",
     "iopub.status.busy": "2025-08-26T13:27:18.705535Z",
     "iopub.status.idle": "2025-08-26T13:27:18.795407Z",
     "shell.execute_reply": "2025-08-26T13:27:18.794835Z",
     "shell.execute_reply.started": "2025-08-26T13:27:18.706067Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now feed this data to a Recurrent Neural Network.\n",
    "\n",
    "❓ **Question** ❓ Write a model that has:\n",
    "- an embedding layer whose `input_dim` is the size of your vocabulary (= your `vocab_size`), and whose `output_dim` is the size of the embedding space you want to have\n",
    "- a RNN (SimpleRNN, LSTM, GRU) layer\n",
    "- a Dense layer\n",
    "- an output layer\n",
    "\n",
    "⚠️ **Warning** ⚠️ Here, you don't need a masking layer. Why? Because `layers.Embedding` has a argument to do that directly, which you have to set with `mask_zero=True`. That also means that your data **HAS TO** be padded with **0** (which is the default behavior). See the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding#example_2) to understand how it **impacts** the `input_dim`.\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Hint</summary>\n",
    "\n",
    "`input_dim` should equal size of vocabulary + 1\n",
    "\n",
    "</details>\n",
    "\n",
    "Compile it with the appropriate arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:29:52.690936Z",
     "iopub.status.busy": "2025-08-26T13:29:52.690241Z",
     "iopub.status.idle": "2025-08-26T13:29:52.806283Z",
     "shell.execute_reply": "2025-08-26T13:29:52.805736Z",
     "shell.execute_reply.started": "2025-08-26T13:29:52.690917Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input, layers\n",
    "\n",
    "embedding_dimension = 50\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=X_train_pad.shape[1:]))\n",
    "\n",
    "model.add(layers.Embedding(input_dim=vocab_size + 1, output_dim=embedding_dimension, mask_zero=True))\n",
    "model.add(layers.LSTM(20))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Look at the number of parameters in your RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:30:08.159094Z",
     "iopub.status.busy": "2025-08-26T13:30:08.158661Z",
     "iopub.status.idle": "2025-08-26T13:30:08.170479Z",
     "shell.execute_reply": "2025-08-26T13:30:08.169922Z",
     "shell.execute_reply.started": "2025-08-26T13:30:08.159072Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1164</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,521,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1164\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │     \u001b[38;5;34m1,521,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m5,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,526,901</span> (5.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,526,901\u001b[0m (5.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,526,901</span> (5.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,526,901\u001b[0m (5.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Double-check that the number of parameters in your embedding layer is equal to the (number of words in your vocabulary + 1 for the masking value) $\\times$  the dimension of your embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:30:55.836030Z",
     "iopub.status.busy": "2025-08-26T13:30:55.835680Z",
     "iopub.status.idle": "2025-08-26T13:30:55.839202Z",
     "shell.execute_reply": "2025-08-26T13:30:55.838621Z",
     "shell.execute_reply.started": "2025-08-26T13:30:55.835982Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of parameters : 1521000\n"
     ]
    }
   ],
   "source": [
    "print(f'Expected number of parameters : {(vocab_size + 1) * embedding_dimension}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Start fitting your model with 20 epochs, with an early stopping criterion whose patience is equal to 4.\n",
    "\n",
    "⚠️ **Warning** ⚠️ You might see that it takes a lot of time! \n",
    "\n",
    "**So stop it after a couple of iterations!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:31:57.673108Z",
     "iopub.status.busy": "2025-08-26T13:31:57.672889Z",
     "iopub.status.idle": "2025-08-26T13:34:23.219124Z",
     "shell.execute_reply": "2025-08-26T13:34:23.218362Z",
     "shell.execute_reply.started": "2025-08-26T13:31:57.673093Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 15:31:58.940860: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 199ms/step - accuracy: 0.5243 - loss: 0.6927 - val_accuracy: 0.6000 - val_loss: 0.6826\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.6386 - loss: 0.6593 - val_accuracy: 0.6640 - val_loss: 0.6775\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 203ms/step - accuracy: 0.7438 - loss: 0.5582 - val_accuracy: 0.6920 - val_loss: 0.5637\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 193ms/step - accuracy: 0.8551 - loss: 0.3893 - val_accuracy: 0.7000 - val_loss: 0.5924\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9337 - loss: 0.2192 - val_accuracy: 0.8013 - val_loss: 0.4241\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 207ms/step - accuracy: 0.9628 - loss: 0.1357 - val_accuracy: 0.7973 - val_loss: 0.5083\n",
      "Epoch 7/20\n",
      "\u001b[1m 65/110\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 183ms/step - accuracy: 0.9790 - loss: 0.0668 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      3\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=16,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not waste too much time just staring at our screen or having coffees. It is too early to start having breaks ;)\n",
    "\n",
    "❓ **Question** ❓ We will reduce the computational time. To start, let's first look at how many words there are in the different sentences of your train set (Just run the following cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:35:27.953250Z",
     "iopub.status.busy": "2025-08-26T13:35:27.952244Z",
     "iopub.status.idle": "2025-08-26T13:35:28.061266Z",
     "shell.execute_reply": "2025-08-26T13:35:28.060658Z",
     "shell.execute_reply.started": "2025-08-26T13:35:27.953219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAGzCAYAAABejHGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARXNJREFUeJzt3XlYVdXi//HPAWRQBEQZxBwQvalpaZCKs0miUWY5lnlx9pZm5swtLVPDbJ6cGtRrmkNzlpqpqd1w1nJKLcf0ApoBDjkA6/dHX/bPI4OoCOh+v56HR1l7nb3XWmefvT/s6TiMMUYAAACwBZeibgAAAAAKD+EPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYyHUPf1WqVFGPHj2u92Js76WXXlLVqlXl6uqqunXrXvHrv//+ezkcDn388ccF37gbgMPh0MCBA4u6GfmSnp6uESNGqGLFinJxcVH79u2LuknIRXH4XFWpUkX33XdfkS2/uGMfdeWKw3p9JZKSktSxY0eVLVtWDodDr7/+elE3Kd9atGihFi1aFPh8ryj8zZw5Uw6HQxs3bsxxeosWLVS7du1rbtQ333yj55577prnYxfffvutRowYocaNG2vGjBl64YUXcq07d+7cG2rFR3YffPCBXnrpJXXs2FGzZs3SU089VdRNcrJz504999xzOnDgQFE3pdAU5ueK7SNwZZ566iktXbpUcXFxmj17ttq0aVPUTSpybtd7Abt375aLy5UdYPzmm2/0zjvvsIHLpxUrVsjFxUXvv/++3N3d86w7d+5cbd++XYMHDy6cxqHArVixQhUqVNBrr71W1E3J0c6dOzV27Fi1aNFCVapUKermFIrC/FyxfSxYV7OPwo1lxYoVeuCBBzRs2LCibkqxcd3XeA8PD5UoUeJ6L6ZAnT59uqibcEWSk5Pl5eV12eCHonX27FllZmZe83ySk5Pl5+d37Q0CcEPuo+yioPbFxXmbWVR5o9Cv+btw4YLGjh2r6tWry9PTU2XLllWTJk20bNkySVKPHj30zjvvSPr7OqysnyynT5/W0KFDVbFiRXl4eOjWW2/Vyy+/LGOM03L/+usvDRo0SOXKlVPp0qXVrl07HTlyRA6Hw+kv5ueee04Oh0M7d+7UI488ojJlyqhJkyaSpJ9//lk9evRQ1apV5enpqeDgYPXq1Ut//PGH07Ky5rFnzx49+uij8vX1VUBAgEaPHi1jjA4fPqwHHnhAPj4+Cg4O1iuvvJKvsUtPT9e4ceMUFhYmDw8PValSRf/+97917tw5q47D4dCMGTN0+vRpa6xmzpyZ4/xatGihr7/+WgcPHrTqXnpkJjMzUxMmTNAtt9wiT09PtWrVSr/++mu2ea1bt05t2rSRr6+vSpYsqebNm+u///3vZfuUda3IggULLruc3K7FufQaiIvnOXbsWFWoUEGlS5dWx44dlZqaqnPnzmnw4MEKDAyUt7e3evbs6TSGF5szZ45uvfVWeXp6Kjw8XKtXr85W58iRI+rVq5eCgoLk4eGh2267TR988EGO/Zw3b56eeeYZVahQQSVLllRaWlquY3O5dfvAgQNyOBxauXKlduzYYb2H33//fa7z3Lhxo6Kjo1WuXDl5eXkpNDRUvXr1cqqTmZmp119/Xbfddps8PT0VFBSk/v37688//3Sql3Xt2A8//KD69evL09NTVatW1X/+8x+rzsyZM9WpUydJUsuWLXNs4+LFi9W0aVOVKlVKpUuXVkxMjHbs2OG0rB49esjb21tHjhxR+/bt5e3trYCAAA0bNkwZGRnZ2v/GG2+oTp068vT0VEBAgNq0aZPt8pQPP/xQ4eHh8vLykr+/v7p27arDhw871dm7d686dOig4OBgeXp66pZbblHXrl2Vmpqa6xgX1OdqzZo16tSpkypVqiQPDw9VrFhRTz31lP766y+ncclr+5iXvN43STpx4oSGDRumOnXqyNvbWz4+Pmrbtq1++uknq05SUpLc3Nw0duzYbPPfvXu3HA6H3n77bassJSVFgwcPttbpatWq6cUXX8zXH0FffPGFYmJiFBISIg8PD4WFhWncuHHZ3v/cfP/994qIiJCnp6fCwsI0bdo0a1t9sYu3Mxs3bpTD4dCsWbOyzW/p0qVyOBxatGiRVXYl24L8bPNyktXmX3/9VT169JCfn598fX3Vs2dPnTlzxqqXtX3Iafuf237vWvdZGRkZ+ve//63g4GCVKlVK7dq1y/aZkvK3v8hrX5ybffv2qVOnTvL391fJkiXVsGFDff3119b0rEvVjDF65513Lvt5ufPOO/XQQw85ldWpU0cOh0M///yzVTZ//nw5HA7t2rXLKtuyZYvatm0rHx8feXt7q1WrVlq7dq3TvLLas2rVKj3++OMKDAzULbfcYk2fPn26wsLC5OXlpfr162vNmjU5tvOtt97SbbfdppIlS6pMmTKKiIjQ3Llz8xyrS13Vad/U1FQdP348W/mFCxcu+9rnnntO8fHx6tOnj+rXr6+0tDRt3LhRmzdv1j333KP+/fvr6NGjWrZsmWbPnu30WmOM2rVrp5UrV6p3796qW7euli5dquHDh+vIkSNOp8F69OihBQsWqHv37mrYsKFWrVqlmJiYXNvVqVMnVa9eXS+88IK1s122bJn27dunnj17Kjg4WDt27ND06dO1Y8cOrV27NttK1KVLF9WsWVMTJ07U119/rfHjx8vf31/Tpk3T3XffrRdffFFz5szRsGHDdNddd6lZs2Z5jlWfPn00a9YsdezYUUOHDtW6desUHx+vXbt26bPPPpMkzZ49W9OnT9f69ev13nvvSZIaNWqU4/yefvpppaam6vfff7fGytvb26nOxIkT5eLiomHDhik1NVWTJk1St27dtG7dOqvOihUr1LZtW4WHh+vZZ5+Vi4uLZsyYobvvvltr1qxR/fr18+xXfpdzpeLj4+Xl5aVRo0bp119/1VtvvaUSJUrIxcVFf/75p5577jmtXbtWM2fOVGhoqMaMGeP0+lWrVmn+/PkaNGiQPDw8NHnyZLVp00br16+3rmVNSkpSw4YNrRtEAgICtHjxYvXu3VtpaWnZTvuNGzdO7u7uGjZsmM6dO5fr0dn8rNsBAQGaPXu2JkyYoFOnTik+Pl6SVLNmzRznmZycrNatWysgIECjRo2Sn5+fDhw4oE8//dSpXv/+/TVz5kz17NlTgwYN0v79+/X2229ry5Yt+u9//+t0VOTXX39Vx44d1bt3b8XGxuqDDz5Qjx49FB4erttuu03NmjXToEGD9Oabb+rf//631basf2fPnq3Y2FhFR0frxRdf1JkzZzRlyhQ1adJEW7ZscQpNGRkZio6OVoMGDfTyyy/ru+++0yuvvKKwsDA99thjVr3evXtr5syZatu2rfr06aP09HStWbNGa9euVUREhCRpwoQJGj16tDp37qw+ffro2LFjeuutt9SsWTNt2bJFfn5+On/+vKKjo3Xu3Dk98cQTCg4O1pEjR7Ro0SKlpKTI19c3x3EuqM/VwoULdebMGT322GMqW7as1q9fr7feeku///67Fi5caL1XuW0f83K59036e0f6+eefq1OnTgoNDVVSUpKmTZum5s2ba+fOnQoJCVFQUJCaN2+uBQsW6Nlnn3Vaxvz58+Xq6mqF/zNnzqh58+Y6cuSI+vfvr0qVKunHH39UXFyc/ve//132GsmZM2fK29tbQ4YMkbe3t1asWKExY8YoLS1NL730Up6v3bJli9q0aaPy5ctr7NixysjI0PPPP6+AgIA8XxcREaGqVatqwYIFio2Nzda/MmXKKDo6WtKVbwuudZvXuXNnhYaGKj4+Xps3b9Z7772nwMBAvfjii/l6fU6udZ81YcIEORwOjRw5UsnJyXr99dcVFRWlrVu3ysvLS9KV7y9y2hfnJCkpSY0aNdKZM2c0aNAglS1bVrNmzVK7du308ccf68EHH1SzZs00e/Zsde/eXffcc4/++c9/5jkeTZs21UcffWT9fuLECe3YsUMuLi5as2aNbr/9dkl//6EWEBBgbdd27Nihpk2bysfHRyNGjFCJEiU0bdo0tWjRQqtWrVKDBg2clvP4448rICBAY8aMsY78vf/+++rfv78aNWqkwYMHa9++fWrXrp38/f1VsWJF67XvvvuuBg0apI4dO+rJJ5/U2bNn9fPPP2vdunV65JFH8uyfE3MFZsyYYSTl+XPbbbc5vaZy5comNjbW+v2OO+4wMTExeS5nwIABJqemff7550aSGT9+vFN5x44djcPhML/++qsxxphNmzYZSWbw4MFO9Xr06GEkmWeffdYqe/bZZ40k8/DDD2db3pkzZ7KVffTRR0aSWb16dbZ59OvXzypLT083t9xyi3E4HGbixIlW+Z9//mm8vLycxiQnW7duNZJMnz59nMqHDRtmJJkVK1ZYZbGxsaZUqVJ5zi9LTEyMqVy5crbylStXGkmmZs2a5ty5c1b5G2+8YSSZbdu2GWOMyczMNNWrVzfR0dEmMzPTqnfmzBkTGhpq7rnnnjyXn9/lGJN93cnSvHlz07x582zzrF27tjl//rxV/vDDDxuHw2Hatm3r9PrIyMhsY5C1/m7cuNEqO3jwoPH09DQPPvigVda7d29Tvnx5c/z4cafXd+3a1fj6+lrrTFabqlatmuN6dKn8rttZ/b/0c5aTzz77zEgyGzZsyLXOmjVrjCQzZ84cp/IlS5ZkK69cuXK2dT85Odl4eHiYoUOHWmULFy40kszKlSud5nny5Enj5+dn+vbt61SemJhofH19ncpjY2ONJPP888871a1Xr54JDw+3fl+xYoWRZAYNGpStb1nr54EDB4yrq6uZMGGC0/Rt27YZNzc3q3zLli1Gklm4cGH2gbqMa/1cGZPz9iY+Pt44HA5z8OBBqyy37WNu8vu+nT171mRkZDi9dv/+/cbDw8PpfZg2bVq2thtjTK1atczdd99t/T5u3DhTqlQps2fPHqd6o0aNMq6urubQoUN5tjun8ejfv78pWbKkOXv2bJ6vvf/++03JkiXNkSNHrLK9e/caNze3bGN36XYmLi7OlChRwpw4ccIqO3funPHz8zO9evWyyq50W5CfdSAnWfuXi5dtjDEPPvigKVu2rPX7/v37jSQzY8aMbPPIbb93tfusrD5VqFDBpKWlWeULFiwwkswbb7xhjLmy/UVe++KcDB482Egya9asscpOnjxpQkNDTZUqVZzWZUlmwIABl51n1rZr586dxhhjvvzyS+Ph4WHatWtnunTpYtW7/fbbnfYL7du3N+7u7ua3336zyo4ePWpKly5tmjVrZpVlZagmTZqY9PR0q/z8+fMmMDDQ1K1b12kdmT59upHktL974IEH8rX9v5yrOu37zjvvaNmyZdl+slJxXvz8/LRjxw7t3bv3ipf7zTffyNXVVYMGDXIqHzp0qIwxWrx4sSRpyZIlkv5O1xd74okncp33v/71r2xlWX+5SH9fr3X8+HE1bNhQkrR58+Zs9fv06WP939XVVRERETLGqHfv3la5n5+fbr31Vu3bty/Xtkh/91WShgwZ4lQ+dOhQSXI6tF2Qevbs6XR0qmnTppJktXfr1q3au3evHnnkEf3xxx86fvy4jh8/rtOnT6tVq1ZavXp1vk7pXG45V+Of//yn01GqBg0ayBiT7TRngwYNdPjwYaWnpzuVR0ZGKjw83Pq9UqVKeuCBB7R06VJlZGTIGKNPPvlE999/v4wxVt+PHz+u6OhopaamZlsvYmNjndaj3OR33b4SWde4LFq0KNej8gsXLpSvr6/uuecep/6Eh4fL29tbK1eudKpfq1Yt672SpICAgHytz9LfR9JTUlL08MMPOy3L1dVVDRo0yLYsKfvnsmnTpk7L+uSTT+RwOLIdhZJkHZn/9NNPlZmZqc6dOzstNzg4WNWrV7eWm3Vkb+nSpU6n0wpCftb3i9eT06dP6/jx42rUqJGMMdqyZcs1LT8/75uHh4d140NGRob++OMPeXt769Zbb3Varx966CG5ublp/vz5Vtn27du1c+dOdenSxSpbuHChmjZtqjJlyjiNe1RUlDIyMnK8pOJiF4/HyZMndfz4cTVt2lRnzpzRL7/8kuvrMjIy9N1336l9+/YKCQmxyqtVq6a2bdvmuUzp76NhFy5ccDpC/u233yolJcXq39VsC651m5fTZ+GPP/7I81KSy7nWfdY///lPlS5d2vq9Y8eOKl++vLX/upr9RU774px88803ql+/vtOpYW9vb/Xr108HDhzQzp078zcIF8l6T7LWzTVr1uiuu+7SPffcY52CTUlJ0fbt2626GRkZ+vbbb9W+fXtVrVrVmlf58uX1yCOP6Icffsj2HvXt21eurq7W7xs3blRycrL+9a9/Oa0jPXr0yHbGwc/PT7///rs2bNhwxf272FWd9q1fv751OuViWR/yvDz//PN64IEH9I9//EO1a9dWmzZt1L1793wFx4MHDyokJMRpZZP+/ymlgwcPWv+6uLgoNDTUqV61atVynfeldaW/D/mOHTtW8+bNU3JystO0nK4BqlSpktPvvr6+8vT0VLly5bKVX3rd4KWy+nBpm4ODg+Xn52f1taBd2ocyZcpIknX9V1Zov/SUyMVSU1Ot113tcq5GTuMvyemQeVZ5ZmamUlNTVbZsWau8evXq2eb5j3/8Q2fOnNGxY8fk4uKilJQUTZ8+XdOnT8+xDZeuJzmtVznJ77p9JZo3b64OHTpo7Nixeu2119SiRQu1b99ejzzyiDw8PCT9/X6mpqYqMDAwx3lc2p9Lx1j6+73Lz/uWte7cfffdOU738fFx+j3r+r28lvXbb78pJCRE/v7+eS7XGJPj+yvJ+oMhNDRUQ4YM0auvvqo5c+aoadOmateunXVN1LXIz/p+6NAhjRkzRl9++WW28czrmsOrWX5WGy5eTta1k5MnT9b+/fudrq27+HNSrlw5tWrVSgsWLNC4ceMk/X1K1M3Nzel6qb179+rnn3/O9VTrpevWpXbs2KFnnnlGK1asyLbzzGs8kpOT9ddff+W4vc9rH5DljjvuUI0aNTR//nwrBM2fP1/lypWz1t1jx45d8bbgWrd5eb3+0s9Ofl3rPuvSz5TD4VC1atWsxzxdzf7iSraZl55OlZy3mVf66LmgoCBVr15da9asUf/+/bVmzRq1bNlSzZo10xNPPKF9+/Zp165dyszMtMLfsWPHdObMGd166605tiUzM1OHDx+2Lq/IqY9Z2/dLx7NEiRJOgVKSRo4cqe+++07169dXtWrV1Lp1az3yyCNq3LjxFfX1uj/q5VLNmjXTb7/9pi+++ELffvut3nvvPb322muaOnWq018hhS2nozOdO3fWjz/+qOHDh6tu3bry9vZWZmam2rRpk+PRrYuTfF5lkvK8luFi+b2Yu6Bcrr1Z/X7ppZdyfZj0pdc7Xc1ypNz7npGRcUVjfa3vQZasvj/66KO5bswu/SMmP0f9rpesh7CuXbtWX331lZYuXapevXrplVde0dq1a631OTAwUHPmzMlxHpfuuK9lLLPGb/bs2QoODs423c3NeXOU27KuVGZmphwOhxYvXpzjPC9eX1955RX16NHD2j4NGjRI8fHxWrt2rdOF2VfqcuOWkZGhe+65RydOnNDIkSNVo0YNlSpVSkeOHFGPHj2u+S7x/LxvL7zwgkaPHq1evXpp3Lhx8vf3l4uLiwYPHpxt+V27dlXPnj21detW1a1bVwsWLFCrVq2cQkNmZqbuuecejRgxIsdl/+Mf/8i1vSkpKWrevLl8fHz0/PPPKywsTJ6entq8ebNGjhxZIHfN56VLly6aMGGCjh8/rtKlS+vLL7/Uww8/bK2jV7MtuNbt0OVen9f28krmWVDbS+nq9hdFuc2UpCZNmmj58uX666+/tGnTJo0ZM0a1a9eWn5+f1qxZo127dsnb21v16tW76mVcSx9r1qyp3bt3a9GiRVqyZIk++eQTTZ48WWPGjMnxRqzcFHr4kyR/f3/17NlTPXv21KlTp9SsWTM999xzVvjLbSWuXLmyvvvuO508edLpCEnWKYDKlStb/2ZmZmr//v1OSTo/d1Zl+fPPP7V8+XKNHTvW6caAqzldfTWy+rB3716nC/qTkpKUkpJi9fVKXWuYDAsLk/T3UZqoqKhrmtfllClTRikpKdnKDx48mO2voYKQ03u7Z88elSxZ0gpBpUuXVkZGRoH3Pb/r9tVo2LChGjZsqAkTJmju3Lnq1q2b5s2bpz59+igsLEzfffedGjduXGAb3dzWsax1JzAwsMDGLywsTEuXLtWJEydyPfoXFhYmY4xCQ0PzDBxZ6tSpozp16uiZZ57Rjz/+qMaNG2vq1KkaP358rq+51s/Vtm3btGfPHs2aNcvpovSspyAU5LJy8/HHH6tly5Z6//33ncpTUlKyHQlq3769+vfvb5363bNnj+Li4pzqhIWF6dSpU1f1Xn///ff6448/9OmnnzrdZLB///7LvjYwMFCenp45bu/zuw/o0qWLxo4dq08++URBQUFKS0tT165drekBAQHXbVtwtbKOnl26zbxeZ4mk7NtMY4x+/fVXK/hez/1F5cqVtXv37mzl17rNbNq0qWbMmKF58+YpIyNDjRo1kouLi5o0aWKFv0aNGlkhOSAgQCVLlsy1LS4uLtnOPuXUF+nv8bz4zMiFCxe0f/9+3XHHHU71S5UqpS5duqhLly46f/68HnroIU2YMEFxcXHy9PTMVz8L/cmWlx469vb2VrVq1ZwevVGqVClJ2Vfie++9VxkZGU6PEpCk1157TQ6Hw7qeI+turMmTJzvVe+utt/Ldzqw39tK/dgrrKf733ntvjst79dVXJSnPO5fzUqpUqWs6hRQeHq6wsDC9/PLLOnXqVLbpx44du+p5XyosLExr167V+fPnrbJFixbl+CiBgpCQkOB0nc7hw4f1xRdfqHXr1nJ1dZWrq6s6dOigTz75RNu3b8/2+mvpe37X7Svx559/Zlt/s/76zvq8de7cWRkZGdbpu4ulp6fnGL4vJ7fPb3R0tHx8fPTCCy/keA3i1Yxfhw4dZIzJ8S/erL4/9NBDcnV11dixY7ONhzHG2ialpaVluw60Tp06cnFxyfXRQFmu9XOV0/bGGKM33ngjx2VJ2cf3Wrm6umYbn4ULF+rIkSPZ6vr5+Sk6OloLFizQvHnz5O7unu1rBjt37qyEhAQtXbo02+tTUlKyjfWlbZGcx+P8+fPZtum5vTYqKkqff/65jh49apX/+uuv+b52tmbNmqpTp47mz5+v+fPnq3z58k4h9HpuC66Wj4+PypUrl+1ayvyM2dX6z3/+o5MnT1q/f/zxx/rf//5nba+u5/7i3nvv1fr165WQkGCVnT59WtOnT1eVKlVUq1atq5pv1uncF198Ubfffrt1yUfTpk21fPlybdy40en6WVdXV7Vu3VpffPGF07caJSUlae7cuWrSpMllT8tHREQoICBAU6dOddrfzZw5M9vn/NIM5e7urlq1askYk68nrmQp9CN/tWrVUosWLRQeHi5/f39t3LhRH3/8sdP3qmZddD9o0CBFR0fL1dVVXbt21f3336+WLVvq6aef1oEDB3THHXfo22+/1RdffKHBgwdbf2WEh4erQ4cOev311/XHH39Yj3rZs2ePpPz95ezj46NmzZpp0qRJunDhgipUqKBvv/02X395FoQ77rhDsbGxmj59unUKZP369Zo1a5bat2+vli1bXtV8w8PDNX/+fA0ZMkR33XWXvL29df/99+f79S4uLnrvvffUtm1b3XbbberZs6cqVKigI0eOaOXKlfLx8dFXX311VW27VJ8+ffTxxx+rTZs26ty5s3777Td9+OGH1vtc0GrXrq3o6GinR71IcgoWEydO1MqVK9WgQQP17dtXtWrV0okTJ7R582Z99913OnHixFUtO7/r9pWYNWuWJk+erAcffFBhYWE6efKk3n33Xfn4+Fh/XDRv3lz9+/dXfHy8tm7dqtatW6tEiRLau3evFi5cqDfeeEMdO3a8ouXWrVtXrq6uevHFF5WamioPDw/dfffdCgwM1JQpU9S9e3fdeeed6tq1qwICAnTo0CF9/fXXaty4cbbwezktW7ZU9+7d9eabb2rv3r3WJRlZ1+oMHDhQYWFhGj9+vOLi4nTgwAG1b99epUuX1v79+/XZZ5+pX79+GjZsmFasWKGBAweqU6dO+sc//qH09HTNnj3b2tHn5Vo/VzVq1FBYWJiGDRumI0eOyMfHR5988kmO14Pltn28Vvfdd5+ef/559ezZU40aNdK2bds0Z86cXI+yd+nSRY8++qgmT56s6OjobA/RHT58uL788kvdd9991mNlTp8+rW3btunjjz/WgQMHsh1RzNKoUSOVKVNGsbGxGjRokBwOh2bPnp3vU4/PPfecvv32WzVu3FiPPfaY9YdV7dq1tXXr1nzNo0uXLhozZow8PT3Vu3fvbN8Ccr22BdeiT58+mjhxovr06aOIiAitXr3a2u9dD/7+/mrSpIl69uyppKQkvf7666pWrZr69u0r6fruL0aNGqWPPvpIbdu21aBBg+Tv769Zs2Zp//79+uSTT676W1uqVaum4OBg7d692+km0WbNmmnkyJGS5BT+JGn8+PFatmyZmjRposcff1xubm6aNm2azp07p0mTJl12mSVKlND48ePVv39/3X333erSpYv279+vGTNmZPv8tW7dWsHBwWrcuLGCgoK0a9cuvf3224qJicl2zXieruTW4KzblHN7dEROj6C49Db68ePHm/r16xs/Pz/j5eVlatSoYSZMmOD0iI709HTzxBNPmICAAONwOJxuzT958qR56qmnTEhIiClRooSpXr26eemll5xuIzfGmNOnT5sBAwYYf39/4+3tbdq3b292795tJDndxp51e/mxY8ey9ef33383Dz74oPHz8zO+vr6mU6dO5ujRo7neNn/pPHJ7BEt+H9Vx4cIFM3bsWBMaGmpKlChhKlasaOLi4rI95uBKHvVy6tQp88gjjxg/Pz8jyXo8Rdat+5c+5iK3xwds2bLFPPTQQ6Zs2bLGw8PDVK5c2XTu3NksX748z+Vf6XJeeeUVU6FCBePh4WEaN25sNm7cmOujXi6dZ27ra07vl/7vUQAffvihqV69uvHw8DD16tXL9rgSY4xJSkoyAwYMMBUrVjQlSpQwwcHBplWrVmb69OmXbVNe8rtu53f92bx5s3n44YdNpUqVjIeHhwkMDDT33Xef0+NsskyfPt2Eh4cbLy8vU7p0aVOnTh0zYsQIc/ToUatO5cqVc3xM06XvhzHGvPvuu6Zq1arG1dU122NfVq5caaKjo42vr6/x9PQ0YWFhpkePHk7tym2dznrvLpaenm5eeuklU6NGDePu7m4CAgJM27ZtzaZNm5zqffLJJ6ZJkyamVKlSplSpUqZGjRpmwIABZvfu3cYYY/bt22d69eplwsLCjKenp/H39zctW7Y03333Xe6D/H8K4nO1c+dOExUVZby9vU25cuVM3759zU8//ZStXl7bx5zk9307e/asGTp0qClfvrzx8vIyjRs3NgkJCTm+v8YYk5aWZry8vIwk8+GHH+a47JMnT5q4uDhTrVo14+7ubsqVK2caNWpkXn75Zadtfk7++9//moYNGxovLy8TEhJiRowYYZYuXZrjY4Rysnz5clOvXj3j7u5uwsLCzHvvvWeGDh1qPD09s41PTo+U2rt3r/UIqB9++CHHZVzLtiCvR7NcLLf9S9b2bf/+/VbZmTNnTO/evY2vr68pXbq06dy5s0lOTi7wfVZWnz766CMTFxdnAgMDjZeXl4mJiXF6LFGW/Owv8toX5+a3334zHTt2NH5+fsbT09PUr1/fLFq0KFu9rO17fnXq1MlIMvPnz7fKzp8/b0qWLGnc3d3NX3/9le01mzdvNtHR0cbb29uULFnStGzZ0vz4449OdS6XoSZPnmxCQ0ONh4eHiYiIMKtXr872+Zs2bZpp1qyZNZZhYWFm+PDhJjU1Nd/9M8YYhzFXcRXnDWrr1q2qV6+ePvzwQ3Xr1q2omwMAKETt27e/6keNATeTm/bbrC/+SqQsr7/+ulxcXC77zRoAgBvbpfuAvXv36ptvvnH6akjArorkbt/CMGnSJG3atEktW7aUm5ubFi9erMWLF6tfv36XvfMGAHBjq1q1qvXd7AcPHtSUKVPk7u6e66NnADu5aU/7Llu2TGPHjtXOnTt16tQpVapUSd27d9fTTz+d7XliAICbS8+ePbVy5UolJibKw8NDkZGReuGFF3TnnXcWddOAInfThj8AAABkd9Ne8wcAAIDsCH8AAAA2wsVvecjMzNTRo0dVunTpQv+OXQAAcHWMMTp58qRCQkKu+oHPNzPCXx6OHj3KncEAANygDh8+rFtuuaWom1HsEP7ykPVVKYcPH77sd/MBAIDiIS0tTRUrVryyrzyzEcJfHrJO9fr4+BD+AAC4wXDJVs44EQ4AAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBG3om4AbhxVRn1d1E24YgcmxhR1EwAAKFY48gcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARtyKugF2VWXU10XdBAAAYEMc+QMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyl24S8jI0OjR49WaGiovLy8FBYWpnHjxskYY9UxxmjMmDEqX768vLy8FBUVpb179zrN58SJE+rWrZt8fHzk5+en3r1769SpU4XdHQAAgGKl2IW/F198UVOmTNHbb7+tXbt26cUXX9SkSZP01ltvWXUmTZqkN998U1OnTtW6detUqlQpRUdH6+zZs1adbt26aceOHVq2bJkWLVqk1atXq1+/fkXRJQAAgGLDYS4+pFYM3HfffQoKCtL7779vlXXo0EFeXl768MMPZYxRSEiIhg4dqmHDhkmSUlNTFRQUpJkzZ6pr167atWuXatWqpQ0bNigiIkKStGTJEt177736/fffFRISkq+2pKWlydfXV6mpqfLx8SnQfvKcv8JxYGJMUTcBAFDIruf++2ZQ7I78NWrUSMuXL9eePXskST/99JN++OEHtW3bVpK0f/9+JSYmKioqynqNr6+vGjRooISEBElSQkKC/Pz8rOAnSVFRUXJxcdG6detyXfa5c+eUlpbm9AMAAHAzKXbf8DFq1CilpaWpRo0acnV1VUZGhiZMmKBu3bpJkhITEyVJQUFBTq8LCgqypiUmJiowMNBpupubm/z9/a06OYmPj9fYsWMLsjsAAADFSrE78rdgwQLNmTNHc+fO1ebNmzVr1iy9/PLLmjVr1nVfdlxcnFJTU62fw4cPX/dlAgAAFKZid+Rv+PDhGjVqlLp27SpJqlOnjg4ePKj4+HjFxsYqODhYkpSUlKTy5ctbr0tKSlLdunUlScHBwUpOTnaab3p6uk6cOGG9PiceHh7y8PAo4B4BAAAUH8XuyN+ZM2fk4uLcLFdXV2VmZkqSQkNDFRwcrOXLl1vT09LStG7dOkVGRkqSIiMjlZKSok2bNll1VqxYoczMTDVo0KAQegEAAFA8Fbsjf/fff78mTJigSpUq6bbbbtOWLVv06quvqlevXpIkh8OhwYMHa/z48apevbpCQ0M1evRohYSEqH379pKkmjVrqk2bNurbt6+mTp2qCxcuaODAgeratWu+7/QFAAC4GRW78PfWW29p9OjRevzxx5WcnKyQkBD1799fY8aMseqMGDFCp0+fVr9+/ZSSkqImTZpoyZIl8vT0tOrMmTNHAwcOVKtWreTi4qIOHTrozTffLIouAQAAFBvF7jl/xQnP+bvx8Zw/ALAfnvOXt2J3zR8AAACuH8IfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwkWIZ/o4cOaJHH31UZcuWlZeXl+rUqaONGzda040xGjNmjMqXLy8vLy9FRUVp7969TvM4ceKEunXrJh8fH/n5+al37946depUYXcFAACgWCl24e/PP/9U48aNVaJECS1evFg7d+7UK6+8ojJlylh1Jk2apDfffFNTp07VunXrVKpUKUVHR+vs2bNWnW7dumnHjh1atmyZFi1apNWrV6tfv35F0SUAAIBiw2GMMUXdiIuNGjVK//3vf7VmzZocpxtjFBISoqFDh2rYsGGSpNTUVAUFBWnmzJnq2rWrdu3apVq1amnDhg2KiIiQJC1ZskT33nuvfv/9d4WEhOSrLWlpafL19VVqaqp8fHwKpoP/p8qorwt0fsjZgYkxRd0EAEAhu57775tBsTvy9+WXXyoiIkKdOnVSYGCg6tWrp3fffdeavn//fiUmJioqKsoq8/X1VYMGDZSQkCBJSkhIkJ+fnxX8JCkqKkouLi5at25drss+d+6c0tLSnH4AAABuJsUu/O3bt09TpkxR9erVtXTpUj322GMaNGiQZs2aJUlKTEyUJAUFBTm9LigoyJqWmJiowMBAp+lubm7y9/e36uQkPj5evr6+1k/FihULsmsAAABFrtiFv8zMTN1555164YUXVK9ePfXr1099+/bV1KlTr/uy4+LilJqaav0cPnz4ui8TAACgMBW78Fe+fHnVqlXLqaxmzZo6dOiQJCk4OFiSlJSU5FQnKSnJmhYcHKzk5GSn6enp6Tpx4oRVJyceHh7y8fFx+gEAALiZFLvw17hxY+3evdupbM+ePapcubIkKTQ0VMHBwVq+fLk1PS0tTevWrVNkZKQkKTIyUikpKdq0aZNVZ8WKFcrMzFSDBg0KoRcAAADFk1tRN+BSTz31lBo1aqQXXnhBnTt31vr16zV9+nRNnz5dkuRwODR48GCNHz9e1atXV2hoqEaPHq2QkBC1b99e0t9HCtu0aWOdLr5w4YIGDhyorl275vtOXwAAgJtRsQt/d911lz777DPFxcXp+eefV2hoqF5//XV169bNqjNixAidPn1a/fr1U0pKipo0aaIlS5bI09PTqjNnzhwNHDhQrVq1kouLizp06KA333yzKLoEAABQbBS75/wVJzzn78bHc/4AwH54zl/eit01fwAAALh+CH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2UuzD38SJE+VwODR48GCr7OzZsxowYIDKli0rb29vdejQQUlJSU6vO3TokGJiYlSyZEkFBgZq+PDhSk9PL+TWAwAAFC/FOvxt2LBB06ZN0+233+5U/tRTT+mrr77SwoULtWrVKh09elQPPfSQNT0jI0MxMTE6f/68fvzxR82aNUszZ87UmDFjCrsLAAAAxUqxDX+nTp1St27d9O6776pMmTJWeWpqqt5//329+uqruvvuuxUeHq4ZM2boxx9/1Nq1ayVJ3377rXbu3KkPP/xQdevWVdu2bTVu3Di98847On/+fFF1CQAAoMgV2/A3YMAAxcTEKCoqyql806ZNunDhglN5jRo1VKlSJSUkJEiSEhISVKdOHQUFBVl1oqOjlZaWph07duS6zHPnziktLc3pBwAA4GbiVtQNyMm8efO0efNmbdiwIdu0xMREubu7y8/Pz6k8KChIiYmJVp2Lg1/W9KxpuYmPj9fYsWOvsfUAAADFV7E78nf48GE9+eSTmjNnjjw9PQt12XFxcUpNTbV+Dh8+XKjLBwAAuN6KXfjbtGmTkpOTdeedd8rNzU1ubm5atWqV3nzzTbm5uSkoKEjnz59XSkqK0+uSkpIUHBwsSQoODs5292/W71l1cuLh4SEfHx+nHwAAgJtJsQt/rVq10rZt27R161brJyIiQt26dbP+X6JECS1fvtx6ze7du3Xo0CFFRkZKkiIjI7Vt2zYlJydbdZYtWyYfHx/VqlWr0PsEAABQXBS7a/5Kly6t2rVrO5WVKlVKZcuWtcp79+6tIUOGyN/fXz4+PnriiScUGRmphg0bSpJat26tWrVqqXv37po0aZISExP1zDPPaMCAAfLw8Cj0PgEAABQXxS785cdrr70mFxcXdejQQefOnVN0dLQmT55sTXd1ddWiRYv02GOPKTIyUqVKlVJsbKyef/75Imw1AABA0XMYY0xRN6K4SktLk6+vr1JTUwv8+r8qo74u0PkhZwcmxhR1EwAAhex67r9vBsXumj8AAABcP4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALCRG/I5f0B+3YiP1OHxNACA64kjfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALCRYhn+4uPjddddd6l06dIKDAxU+/bttXv3bqc6Z8+e1YABA1S2bFl5e3urQ4cOSkpKcqpz6NAhxcTEqGTJkgoMDNTw4cOVnp5emF0BAAAoVopl+Fu1apUGDBigtWvXatmyZbpw4YJat26t06dPW3WeeuopffXVV1q4cKFWrVqlo0eP6qGHHrKmZ2RkKCYmRufPn9ePP/6oWbNmaebMmRozZkxRdAkAAKBYcBhjTFE34nKOHTumwMBArVq1Ss2aNVNqaqoCAgI0d+5cdezYUZL0yy+/qGbNmkpISFDDhg21ePFi3XfffTp69KiCgoIkSVOnTtXIkSN17Ngxubu7X3a5aWlp8vX1VWpqqnx8fAq0T1VGfV2g88PN48DEmKJuAgDc0K7n/vtmUCyP/F0qNTVVkuTv7y9J2rRpky5cuKCoqCirTo0aNVSpUiUlJCRIkhISElSnTh0r+ElSdHS00tLStGPHjhyXc+7cOaWlpTn9AAAA3EyKffjLzMzU4MGD1bhxY9WuXVuSlJiYKHd3d/n5+TnVDQoKUmJiolXn4uCXNT1rWk7i4+Pl6+tr/VSsWLGAewMAAFC0in34GzBggLZv36558+Zd92XFxcUpNTXV+jl8+PB1XyYAAEBhcivqBuRl4MCBWrRokVavXq1bbrnFKg8ODtb58+eVkpLidPQvKSlJwcHBVp3169c7zS/rbuCsOpfy8PCQh4dHAfcCAACg+CiWR/6MMRo4cKA+++wzrVixQqGhoU7Tw8PDVaJECS1fvtwq2717tw4dOqTIyEhJUmRkpLZt26bk5GSrzrJly+Tj46NatWoVTkcAAACKmWJ55G/AgAGaO3euvvjiC5UuXdq6Rs/X11deXl7y9fVV7969NWTIEPn7+8vHx0dPPPGEIiMj1bBhQ0lS69atVatWLXXv3l2TJk1SYmKinnnmGQ0YMICjewAAwLaKZfibMmWKJKlFixZO5TNmzFCPHj0kSa+99ppcXFzUoUMHnTt3TtHR0Zo8ebJV19XVVYsWLdJjjz2myMhIlSpVSrGxsXr++ecLqxsAAADFzg3xnL+iwnP+UBR4zh8AXBue85e3YnnNHwAAAK4Pwh8AAICNFMtr/gA7uxEvCeBUNQDcODjyBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABtxK+oGALjxVRn1dVE34YodmBhT1E0AgCLBkT8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCF/vBsCWbsSvpJP4WjoA144jfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEZ4yDMA3EBuxIdT82BqoHjhyB8AAICNEP4AAABshPAHAABgI4Q/AAAAG+GGDwDAdXUj3qRyI+LGGuQXR/4AAABshPAHAABgIzd9+HvnnXdUpUoVeXp6qkGDBlq/fn1RNwkAAKDI3NThb/78+RoyZIieffZZbd68WXfccYeio6OVnJxc1E0DAAAoEjd1+Hv11VfVt29f9ezZU7Vq1dLUqVNVsmRJffDBB0XdNAAAgCJx097te/78eW3atElxcXFWmYuLi6KiopSQkJDja86dO6dz585Zv6empkqS0tLSCrx9mefOFPg8AQD2dT32VTeqrLEwxhRxS4qnmzb8HT9+XBkZGQoKCnIqDwoK0i+//JLja+Lj4zV27Nhs5RUrVrwubQQAoKD4vl7ULSh+Tp48KV9f36JuRrFz04a/qxEXF6chQ4ZYv2dmZurEiRMqW7asHA7HZV+flpamihUr6vDhw/Lx8bmeTb3pMHbXhvG7eozd1WPsrh5jd/XyM3bGGJ08eVIhISGF3Lobw00b/sqVKydXV1clJSU5lSclJSk4ODjH13h4eMjDw8OpzM/P74qX7ePjw4f5KjF214bxu3qM3dVj7K4eY3f1Ljd2HPHL3U17w4e7u7vCw8O1fPlyqywzM1PLly9XZGRkEbYMAACg6Ny0R/4kaciQIYqNjVVERITq16+v119/XadPn1bPnj2LumkAAABF4qYOf126dNGxY8c0ZswYJSYmqm7dulqyZEm2m0AKioeHh5599tlsp45xeYzdtWH8rh5jd/UYu6vH2F09xu7aOQz3QQMAANjGTXvNHwAAALIj/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcJfAXrnnXdUpUoVeXp6qkGDBlq/fn1RN6lIxcfH66677lLp0qUVGBio9u3ba/fu3U51zp49qwEDBqhs2bLy9vZWhw4dsn0ry6FDhxQTE6OSJUsqMDBQw4cPV3p6emF2pchNnDhRDodDgwcPtsoYu9wdOXJEjz76qMqWLSsvLy/VqVNHGzdutKYbYzRmzBiVL19eXl5eioqK0t69e53mceLECXXr1k0+Pj7y8/NT7969derUqcLuSqHLyMjQ6NGjFRoaKi8vL4WFhWncuHG6+MEQjN/fVq9erfvvv18hISFyOBz6/PPPnaYX1Dj9/PPPatq0qTw9PVWxYkVNmjTpenftustr7C5cuKCRI0eqTp06KlWqlEJCQvTPf/5TR48edZqHXceuQBgUiHnz5hl3d3fzwQcfmB07dpi+ffsaPz8/k5SUVNRNKzLR0dFmxowZZvv27Wbr1q3m3nvvNZUqVTKnTp2y6vzrX/8yFStWNMuXLzcbN240DRs2NI0aNbKmp6enm9q1a5uoqCizZcsW880335hy5cqZuLi4ouhSkVi/fr2pUqWKuf32282TTz5plTN2OTtx4oSpXLmy6dGjh1m3bp3Zt2+fWbp0qfn111+tOhMnTjS+vr7m888/Nz/99JNp166dCQ0NNX/99ZdVp02bNuaOO+4wa9euNWvWrDHVqlUzDz/8cFF0qVBNmDDBlC1b1ixatMjs37/fLFy40Hh7e5s33njDqsP4/e2bb74xTz/9tPn000+NJPPZZ585TS+IcUpNTTVBQUGmW7duZvv27eajjz4yXl5eZtq0aYXVzesir7FLSUkxUVFRZv78+eaXX34xCQkJpn79+iY8PNxpHnYdu4JA+Csg9evXNwMGDLB+z8jIMCEhISY+Pr4IW1W8JCcnG0lm1apVxpi/P+AlSpQwCxcutOrs2rXLSDIJCQnGmL83EC4uLiYxMdGqM2XKFOPj42POnTtXuB0oAidPnjTVq1c3y5YtM82bN7fCH2OXu5EjR5omTZrkOj0zM9MEBwebl156ySpLSUkxHh4e5qOPPjLGGLNz504jyWzYsMGqs3jxYuNwOMyRI0euX+OLgZiYGNOrVy+nsoceesh069bNGMP45ebSAFNQ4zR58mRTpkwZp8/syJEjza233nqde1R4cgrOl1q/fr2RZA4ePGiMYeyuFad9C8D58+e1adMmRUVFWWUuLi6KiopSQkJCEbaseElNTZUk+fv7S5I2bdqkCxcuOI1bjRo1VKlSJWvcEhISVKdOHadvZYmOjlZaWpp27NhRiK0vGgMGDFBMTIzTGEmMXV6+/PJLRUREqFOnTgoMDFS9evX07rvvWtP379+vxMREp7Hz9fVVgwYNnMbOz89PERERVp2oqCi5uLho3bp1hdeZItCoUSMtX75ce/bskST99NNP+uGHH9S2bVtJjF9+FdQ4JSQkqFmzZnJ3d7fqREdHa/fu3frzzz8LqTdFLzU1VQ6HQ35+fpIYu2t1U3+9W2E5fvy4MjIysn1tXFBQkH755ZcialXxkpmZqcGDB6tx48aqXbu2JCkxMVHu7u7WhzlLUFCQEhMTrTo5jWvWtJvZvHnztHnzZm3YsCHbNMYud/v27dOUKVM0ZMgQ/fvf/9aGDRs0aNAgubu7KzY21up7TmNz8dgFBgY6TXdzc5O/v/9NPXaSNGrUKKWlpalGjRpydXVVRkaGJkyYoG7dukkS45dPBTVOiYmJCg0NzTaPrGllypS5Lu0vTs6ePauRI0fq4Ycflo+PjyTG7loR/lAoBgwYoO3bt+uHH34o6qbcEA4fPqwnn3xSy5Ytk6enZ1E354aSmZmpiIgIvfDCC5KkevXqafv27Zo6dapiY2OLuHXF34IFCzRnzhzNnTtXt912m7Zu3arBgwcrJCSE8UOhu3Dhgjp37ixjjKZMmVLUzblpcNq3AJQrV06urq7Z7rRMSkpScHBwEbWq+Bg4cKAWLVqklStX6pZbbrHKg4ODdf78eaWkpDjVv3jcgoODcxzXrGk3q02bNik5OVl33nmn3Nzc5ObmplWrVunNN9+Um5ubgoKCGLtclC9fXrVq1XIqq1mzpg4dOiTp//c9r89rcHCwkpOTnaanp6frxIkTN/XYSdLw4cM1atQode3aVXXq1FH37t311FNPKT4+XhLjl18FNU52/RxL/z/4HTx4UMuWLbOO+kmM3bUi/BUAd3d3hYeHa/ny5VZZZmamli9frsjIyCJsWdEyxmjgwIH67LPPtGLFimyH38PDw1WiRAmncdu9e7cOHTpkjVtkZKS2bdvm9CHP2ghcuoO/mbRq1Urbtm3T1q1brZ+IiAh169bN+j9jl7PGjRtne6TQnj17VLlyZUlSaGiogoODncYuLS1N69atcxq7lJQUbdq0yaqzYsUKZWZmqkGDBoXQi6Jz5swZubg47xpcXV2VmZkpifHLr4Iap8jISK1evVoXLlyw6ixbtky33nrrTX3aMiv47d27V999953Kli3rNJ2xu0ZFfcfJzWLevHnGw8PDzJw50+zcudP069fP+Pn5Od1paTePPfaY8fX1Nd9//7353//+Z/2cOXPGqvOvf/3LVKpUyaxYscJs3LjRREZGmsjISGt61uNKWrdubbZu3WqWLFliAgICbvrHleTk4rt9jWHscrN+/Xrj5uZmJkyYYPbu3WvmzJljSpYsaT788EOrzsSJE42fn5/54osvzM8//2weeOCBHB/BUa9ePbNu3Trzww8/mOrVq990jyrJSWxsrKlQoYL1qJdPP/3UlCtXzowYMcKqw/j97eTJk2bLli1my5YtRpJ59dVXzZYtW6w7UgtinFJSUkxQUJDp3r272b59u5k3b54pWbLkDf+4krzG7vz586Zdu3bmlltuMVu3bnXaf1x8565dx64gEP4K0FtvvWUqVapk3N3dTf369c3atWuLuklFSlKOPzNmzLDq/PXXX+bxxx83ZcqUMSVLljQPPvig+d///uc0nwMHDpi2bdsaLy8vU65cOTN06FBz4cKFQu5N0bs0/DF2ufvqq69M7dq1jYeHh6lRo4aZPn260/TMzEwzevRoExQUZDw8PEyrVq3M7t27ner88ccf5uGHHzbe3t7Gx8fH9OzZ05w8ebIwu1Ek0tLSzJNPPmkqVapkPD09TdWqVc3TTz/ttNNl/P62cuXKHLdxsbGxxpiCG6effvrJNGnSxHh4eJgKFSqYiRMnFlYXr5u8xm7//v257j9WrlxpzcOuY1cQHMZc9Nh2AAAA3NS45g8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwkf8HEirJRw8A42QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_hist(X):\n",
    "    len_ = [len(_) for _ in X]\n",
    "    plt.hist(len_)\n",
    "    plt.title('Histogram of the number of sentences that have a given number of words')\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably see that 90 to 95% of your sentences have less than 300 words. And very few have more than 1000.\n",
    "\n",
    "However, as you didn't use `maxlen` in your padding above, your input tensor has a dimension equal to the length of the sentence that has the maximum number of words.\n",
    "\n",
    "Now, let's look at how this affects the padding: \n",
    "\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/NLP/tensor_size.png\" alt='Dimensions of the tensor' width=\"700px\" />\n",
    "\n",
    "Because of a few of very long sentences, one dimension of your tensor is equal to around 1000. However, most of the sentences with ~200 words have just padded values that are useless.\n",
    "\n",
    "So your tensor is mostly useless information, which still adds time to the training process.\n",
    "\n",
    "But what if you pad the data to a maximum length (`maxlen`) of say 200 (words)?\n",
    "- First, that would increase the convergence and you would not need to stare at your screen while waiting for the algorithm to converge\n",
    "- But in essence, do you really lose that much information? Do you think that you often need more than 200 words (up to 1000) to tell whether or not a sentence is positive of negative?\n",
    "\n",
    "❓ **Question** ❓ For all these reasons, re-do your padding using the `maxlen` keyword and retrain the model!  See how much faster it is now - without hurting the performance ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:40:00.660604Z",
     "iopub.status.busy": "2025-08-26T13:40:00.660256Z",
     "iopub.status.idle": "2025-08-26T13:40:25.181292Z",
     "shell.execute_reply": "2025-08-26T13:40:25.180633Z",
     "shell.execute_reply.started": "2025-08-26T13:40:00.660580Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9825 - loss: 0.0621 - val_accuracy: 0.8253 - val_loss: 0.5564\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9941 - loss: 0.0291 - val_accuracy: 0.7240 - val_loss: 0.9052\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9921 - loss: 0.0363 - val_accuracy: 0.7933 - val_loss: 0.6403\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9962 - loss: 0.0138 - val_accuracy: 0.8253 - val_loss: 0.7070\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9978 - loss: 0.0132 - val_accuracy: 0.8093 - val_loss: 0.7397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbf381029f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post', maxlen=200)\n",
    "\n",
    "model.fit(X_train_pad, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=16,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Nice, you are now able to use `Tokenizer` and `pad_sequences`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
